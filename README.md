# editor_ia

**editor_ia** is a local tool designed to revise and polish Chinese-to-English webnovel translations â€” especially those generated by machine (MTL) or amateur efforts. It focuses on **clarity, fluency, and readability**, without inventing or altering meaning.

---

## ğŸ§  The Model

Currently uses [`NousResearch/Hermes-2-Pro-Mistral-7B`](https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B) or similar variants (like `OpenHermes`) via Hugging Face, because it:
- runs efficiently on local GPU (CUDA-enabled),
- respects structured prompts with `<|im_start|>` tags,
- avoids hallucinations or censorship,
- provides clean, human-like revisions.

---

## ğŸ“š Why This Exists

Most MTLs or quick fan translations suffer from:
- poor grammar and unnatural flow,
- inconsistent paragraph structure,
- filtered or mangled meaning in key terms.

This tool:
- preserves tone, pacing, idioms, and special terms (e.g., *cultivation*, *immortal*, *dao*),
- never reassigns dialogue or adds content,
- only improves grammar, punctuation, and sentence clarity.

---

## ğŸ”¨ Key Features

### âœ… Block-Based Segmentation
Each chapter is broken into natural **blocks** (typically 3â€“7 lines), ending on punctuation. This ensures LLMs get context-rich but bounded prompts.

### âœ… Strict Prompt Control
The system uses `<|im_start|>`/`<|im_end|>` formatting to define:
- the role of system, user, and assistant,
- what editing is allowed (clarity only, no invention),
- which terms must be preserved.

### ğŸ§  Smart Fallback Handling
If the model fails to revise a block:
1. A second attempt is made with a higher temperature.
2. If it still fails, the original block is kept.
3. Final output integrity is verified â€” no empty blocks are allowed.

This guarantees stable revision across hundreds of blocks.

### ğŸ§¼ Automatic Cleanup
After generation, each block is cleaned via regex to remove:
- chat prompt artifacts (e.g. `<|im_x|>`, `<start>`, `<note>`),
- LLM summaries like â€œThe end.â€ or â€œNo further edits needed.â€,
- empty or repeated Markdown code blocks (like ` ``` `).

This ensures clean output in `.docx`.

### ğŸ§¾ Detailed Logging
Each run creates a log in `dados/logs/` with per-chapter stats:
- Number of blocks,
- Input/output token count,
- Duration,
- Fallback stats:
  - Revised on first try
  - Revised on second try
  - Kept as original
  - Recovered manually after final cleanup

### ğŸ–¥ï¸ Live Terminal Feedback
Terminal shows chapter-by-chapter status and timing, e.g.:

[ğŸ“–] 3/10: Chapter 2003: Surging Will
[âœ…] Finalizado: Chapter 2003: Surging Will (1m 55s)

## ğŸš€ How to Use

1. Place your `.docx` file(s) in `dados/entrada/`.
2. Run `app.py`, or call `revisar_docx_otimizado()` directly.
3. The reviewed version will appear in `dados/saida/`.
4. Logs are stored in `dados/logs/`.

You can configure:
- the model, temperature, and prompt via `utils/config.py`.

---

## ğŸ“ Project Structure

editor_ia/
â”œâ”€â”€ app.py
â”œâ”€â”€ dados/
â”‚ â”œâ”€â”€ entrada/
â”‚ â”œâ”€â”€ saida/
â”‚ â””â”€â”€ logs/
â”œâ”€â”€ modelo/
â”‚ â””â”€â”€ carregador.py
â”œâ”€â”€ processamento/
â”‚ â”œâ”€â”€ segmentador.py
â”‚ â”œâ”€â”€ revisor_llm.py
â”œâ”€â”€ editor/
â”‚ â””â”€â”€ editor_docx.py
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ config.py
â”‚ â””â”€â”€ logger.py

yaml
Copiar
Editar

---

## â±ï¸ Performance

On an RTX 4080:
- ~2,500 tokens per chapter
- 2â€“3 minutes per chapter

Performance depends on number of chapters and block segmentation.

---

## ğŸ”’ Disclaimer

This is a personal tool for cleaning up legally acquired material.  
No content is hosted, redistributed, or republished.

---

## âœï¸ Built by

Developed by **Roman Brocki** with efficiency, modularity, and quality in mind â€” focused on fast, GPU-accelerated processing of long-form fiction with high fidelity to the source.